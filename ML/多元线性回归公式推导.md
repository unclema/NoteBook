线性多元回归可以写为：$f(x_i) = w_1x_{i1} + w_2x_{i2}...w_dx_{id} + b$

将b改名为：$w_{d+1}\times1$

则可变为：$f(x_i) = w_1x_{i1} + w_2x_{i2}...w_dx_{id} + w_{d+1}\times1$

写成矩阵形式：$$f(x_i)=\begin{pmatrix} 
w_1&w_2&...&w_d&w_{d+1}
\end {pmatrix} 
\begin{pmatrix} 
x_{i1}\\
x_{i2}\\
...\\
x_{id}\\
1
\end {pmatrix} 
\\$$

令：$\begin{pmatrix} 
w_1&w_2&...&w_d&w_{d+1}
\end {pmatrix} $为$\hat w^T$

令：$\begin{pmatrix} 
x_{i1}\\
x_{i2}\\
...\\
x_{id}\\
1
\end {pmatrix}$为$\hat x_i$

则：$f(\hat x) =\hat w ^T \hat x_i $

本文讲解的就是如何求解$\hat w $

思路同一元线性回归相同，由最小二乘法得损失函数，证明损失函数为凸函数，对损失函数关于$\hat w$求异界导数，令一阶导数为0求得$\hat w^*$

# 一、由最小二乘法导出损失函数c$E_{\hat w}$

$$
\begin {aligned}
 E_{\hat w} &= \sum_{i=1}^m(y_i - f(\hat x_i))^2\\
 E_{\hat w} &= \sum_{i=1}^m(y_i- \hat w^T \hat x_i)^2\\
 

\end{aligned}
$$

## 1.1 将损失函数向量化

### 1.1.1 定义向量矩阵

$$
\begin{aligned}
X &=
\begin{pmatrix}
x_{11} &x_{12}&...&x_{1d}&1\\
x_{21} &x_{22}&...&x_{2d}&1\\
\cdots &\cdots&\ddots&\cdots&\cdots\\

x_{m1}&x_{m2}&...&x_{md}&1
\end{pmatrix}
=
\begin{pmatrix}
x_1^T&1\\
x_2^T&1\\
\cdots&\cdots\\

x_m^t&1
\end{pmatrix}
=
\begin{pmatrix}
\hat x_1^T\\
\hat x_2^T\\
\vdots\\
\hat x_m^T
\end{pmatrix}\\
y &=
\begin {pmatrix}
y_1&y_2&...&y_m
\end{pmatrix}^T
\end{aligned}
$$

$(x_{11} x_{12}...x_{1d})$为样本，X为样本矩阵

### 1.1.2 进行向量化

$$
\begin{aligned}
 E_{\hat w} &= \sum_{i=1}^m(y_i- \hat w^T \hat x_i)^2
 \\
 E_{\hat w}&= (y_1- \hat w^T \hat x_1)^2+(y_2- \hat w^T \hat x_2)^2+...+
 (y_m- \hat w^T \hat x_m)^2
 \\
 E_{\hat w} &=
 \begin{pmatrix}
 y_1- \hat w^T \hat x_1&y_2- \hat w^T \hat x_2&...&y_d- \hat w^T \hat x_d
 \end{pmatrix}
 \begin{pmatrix}
 y_1- \hat w^T \hat x_1 \\
 y_2- \hat w^T \hat x_2 \\
 \vdots
 \\
 y_d- \hat w^T \hat x_d
 \end{pmatrix}\\
 
\end{aligned}
$$

又因为：
$$
\begin{pmatrix}
 y_1- \hat w^T \hat x_1 \\
 y_2- \hat w^T \hat x_2 \\
 \vdots
 \\
 y_d- \hat w^T \hat x_d
 \end{pmatrix}=
 \begin{pmatrix}
 y_1\\
 y_2\\
\vdots
\\
 y_d
 \end{pmatrix}
 -
 \begin{pmatrix}
 \hat w^T \hat x_1\\
 \hat w^T \hat x_2\\
 \vdots
 \\
 \hat w^T \hat x_d
 \end{pmatrix}
 =
 \begin{pmatrix}
 y_1\\
 y_2\\
\vdots
\\
 y_d
 \end{pmatrix}
 -
 \begin{pmatrix}
 \hat x^T_1 \hat w \\
 \hat x^T_2 \hat w \\
 \vdots
 \\
 \hat x^T_d \hat w 
 \end{pmatrix}
 =
 \begin{pmatrix}
 y_1\\
 y_2\\
\vdots
\\
 y_d
 \end{pmatrix}
 -
 \begin{pmatrix}
 \hat x^T_1 \\
 \hat x^T_2\\
 \vdots
 \\
 \hat x^T_d
 \end{pmatrix}
  \hat w
$$

> 因为$\hat w^T \hat x$为标量所以$\hat w^T \hat x = \hat x \hat w^T$

故：

$E_{\hat w} = (y-X\hat w)^T(y-X\hat w)$

# 二、证明损失函数为凸函数

##  2.1数学依据

### 2.1.1 凸集定义

设集合$D\in R^n $,如果对任意的$x,y \in D$与任意的$a \in [0,1]$,有$ax + (1-a) \in D$则城集合$D$是凸集。

凸集几何意义：若两点属于此集合，则这两点连线上的任意一点均属于此集合

![](https://gitee.com/unclema/picture_bed/raw/master/img/20200814114758.png)

### 2.1.2 梯度定义

设n元函数$f(x)$对自变量$x=(x_1,x_2,...，x_n)^T$的各分量$x_i$的偏导数$\frac{\partial f(x)}{\partial x_i}(i=1,2,...,n)$都存在，则称函数$f(x)$在x处一阶可导，并称向量
$$
\nabla f(x)=
\begin{pmatrix}
\frac{\partial f(x)}{\partial x_1}\\
\frac{\partial f(x)}{\partial x_2}\\
.\\
.\\
\frac{\partial f(x)}{\partial x_n}\\
\end{pmatrix}
$$
为函数$f(x)$在x处的一阶导数或梯度，记为$\nabla f{x}$(列向量)

### 2.1.3 海塞矩阵

Hessian矩阵定义：设n元函数$f(x)$对自变量$x=(x_1,x_2,...,x_n)^T$的各分量$x_i$的二阶偏导数$\frac{\partial^2f(x)}{\partial x_i \partial x_j}（i=1,2,...,n;j=1,2,...,n)$都存在，则称函数$f(x)$在x处二阶可导，并称矩阵
$$
\nabla ^2f(x)=
\begin {bmatrix}
\frac{\partial^2f(x)}{\partial x^2_1} &
\frac{\partial^2f(x)}{\partial x_1 \partial x_2}&
\cdot \cdot \cdot&
\frac{\partial^2f(x)}{\partial x_1 \partial x_n}
\\
\frac{\partial^2f(x)}{\partial x_2 \partial x_1} &
\frac{\partial^2f(x)}{\partial x^2_2} &
\cdot \cdot \cdot&
\frac{\partial^2f(x)}{\partial x_2 \partial x_n}
\\
\vdots & \vdots & \ddots & \vdots
\\
\frac{\partial^2f(x)}{\partial x_n \partial x_1} &
\frac{\partial^2f(x)}{\partial x_n \partial x_2} &
\cdots &
\frac{\partial^2f(x)}{\partial x^2_n}
\end {bmatrix}
$$
为$f(x)$在x处的二阶导数或$Hessian$矩阵，记为$\nabla ^2 f(x)$,若$f(x)$对$x$各变元的所有二阶偏导数都连续，则$\frac {\partial ^2 f(x)}{\partial x_i \partial x_j} = \frac {\partial ^2 f(x)}{\partial x_j \partial x_i}$此时$\nabla ^2 f(x)$为对称矩阵。

### 2.1.4 多元实值函数凹凸性判定定理

设$D \subset R^n$是非空开凸集，$f:D\subset R^n \to R$且 $f(x)$在D上二阶连续可微，如果f(x)的海塞矩阵$\nabla ^2 f(x)$在D上是正定的，则 f(x)是D上的严格凸函数

> $f:D\subset R^n \to R$输入是n维向量输出是实数

### 2.1.5凸充分定理

若$f: R^n \to R$是凸函数，且$f(x)$一阶连续可微，则$x^*$是全局解的充分必要条件是$\nabla f(x^*) = 0$,其中$\nabla f(x)$为$f(x)$关于$x$的一阶导师（也称梯度）。

### 2.1.6 矩阵微分知识

【标量-向量】的矩阵微分公式为：
$$
\frac{\partial y}{\partial x} =
\begin{pmatrix}
\frac{\partial y}{\partial x_1} \\
\frac{\partial y}{\partial x_2} \\
\vdots\\
\frac{\partial y}{\partial x_n}\\
\end{pmatrix}\\
(分母布局)【默认】
$$

$$
\frac{\partial y}{\partial x} =
\begin{pmatrix}
\frac{\partial y}{\partial x_1} &
\frac{\partial y}{\partial x_2} &
\cdots&
\frac{\partial y}{\partial x_n}&
\end{pmatrix}\\
(分子布局)
$$

其中$x=(x_1,x_2,\cdots,x_n)^T$为n维列向量，$y$为$x$的n元标量函数

由【标量-向量公式】可推得
$$
\frac {\partial x^T a}{\partial x} = 
\frac {\partial a^Tx}{\partial x} =
\begin {pmatrix}
\frac {\partial (a_1x_1+a_2x_2+\cdots+a_nx_n)}{\partial x_1}
\\

\frac {\partial (a_1x_1+a_2x_2+\cdots+a_nx_n)}{\partial x_2}\\
\vdots\\

\frac {\partial (a_1x_1+a_2x_2+\cdots+a_nx_n)}{\partial x_n}
\end{pmatrix}
=
\begin{pmatrix}
a_1\\
a_2\\
\vdots\\
a_n
\end{pmatrix}
= a
$$


## 2.2 证明凸函数
求解一阶偏导数
$$
\begin {aligned}
\frac{\partial E_{\hat w}}{\partial \hat w}
 &= \frac {\partial}{\partial \hat w}(y-X\hat w)^T(y-X\hat w)
\\
&=\frac {\partial}{\partial \hat w} (y^T-\hat w^TX^T)(y-X\hat w)
\\
&=\frac {\partial}{\partial \hat w} (y^Ty-y^TX\hat w - \hat w^TX^Ty+\hat w^TX^TX\hat w)
\\
&=\frac {\partial}{\partial \hat w} (-y^TX\hat w - \hat w^TX^Ty+\hat w^TX^TX\hat w)\\
&= -\frac {\partial y^TX\hat w}{\partial \hat w}  - \frac {\partial \hat w^TX^Ty}{\partial \hat w}  +\frac {\partial \hat w^TX^TX\hat w}{\partial \hat w} 
\\
由矩阵微分公式
\frac {\partial x^T a}{\partial x} &= 
\frac {\partial a^Tx}{\partial x} = a，
\frac{\partial x^TBx}{\partial x} = (B+B^T)x可得
\\
\frac{\partial E_{\hat w}}{\partial \hat w}
&= -X^Ty-X^Ty+(X^TX+X^TX)\hat w
\\
\frac{\partial E_{\hat w}}{\partial \hat w}
&=2X^T(X\hat w - y)
\end{aligned}
$$
求解二阶偏导数
$$
\begin {aligned}
\frac{\partial^2 E_{\hat w}}{\partial \hat w \partial \hat w^T}
&=
\frac{\partial}{\partial \hat w}\frac{\partial E_{\hat w}}{\partial \hat w}
\\
&=\frac{\partial}{\partial \hat w}[2X^T(X\hat w - y)]
\\
&= \frac{\partial}{\partial \hat w}(2X^TX\hat w - 2X^Ty)
\\
&= \frac{\partial}{\partial \hat w}(2X^TX\hat w)
\\
&= 2(X^TX)^T
\\
&= 2X^TX（此即为海塞矩阵）
\end{aligned}
$$

这个海塞矩阵并不一定为正定矩阵，所以在求$w^*$时必须先规定为正定矩阵才行

# 三、令一阶导数为0求得$\hat w^*$

# 

$$
\begin{aligned}
\frac{\partial E_{\hat w}}{\partial \hat w}
&=2X^T(X\hat w - y) = 0
\\
2X^TX\hat w - 2X^Ty &= 0 
\\
2X^TX\hat w &= 2X^Ty 
\\
两边同乘(X^TX)^{-1}&
\\
\hat w &= (X^TX)^{-1}X^Ty
\end{aligned}
$$

